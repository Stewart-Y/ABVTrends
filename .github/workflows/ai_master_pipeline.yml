name: AI Engineering Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: "0 */4 * * *"  # Run every 4 hours
  workflow_dispatch:
    inputs:
      run_refactor:
        description: 'Run refactoring agent'
        required: false
        default: 'false'
        type: boolean
      run_test_generation:
        description: 'Generate new tests'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  # ==================== Backend Analysis ====================
  backend-analysis:
    name: Backend Code Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install anthropic sqlalchemy bandit pytest pytest-asyncio httpx

      - name: Install backend dependencies
        working-directory: backend
        run: pip install -r requirements.txt
        continue-on-error: true

      - name: Run Model Auditor
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python backend/model_auditor.py
        continue-on-error: true

      - name: Run Performance Analyzer
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python backend/performance_analyzer.py
        continue-on-error: true

      - name: Run Log Analyzer
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          if [ -f "../../backend/app.log" ]; then
            python backend/log_analyzer.py ../../backend/app.log
          else
            echo "No log file found, skipping log analysis"
          fi
        continue-on-error: true

      - name: Upload Analysis Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-analysis
          path: |
            frontend/tests/ai/results/model_audit*.md
            frontend/tests/ai/results/performance_report*.md
            frontend/tests/ai/results/log_analysis*.md
          retention-days: 14

  # ==================== Security Scan ====================
  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install anthropic bandit

      - name: Run Bandit Security Scan
        run: |
          bandit -r backend/ -f json -o frontend/tests/ai/results/security_raw.json --exit-zero
        continue-on-error: true

      - name: Run AI Security Analysis
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python security/security_analyzer.py
        continue-on-error: true

      - name: Upload Security Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-report
          path: |
            frontend/tests/ai/results/security_report*.md
            frontend/tests/ai/results/security_raw.json
          retention-days: 14

  # ==================== Test Generation ====================
  generate-tests:
    name: Generate Backend Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.run_test_generation == 'true' || github.event_name == 'schedule'
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install anthropic pytest pytest-asyncio httpx

      - name: Generate Unit Tests
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python backend/unit_test_generator.py
        continue-on-error: true

      - name: Generate Integration Tests
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python backend/integration_test_generator.py
        continue-on-error: true

      - name: Upload Generated Tests
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: generated-tests
          path: |
            backend/tests/
            frontend/tests/ai/results/unit_tests_generated*.json
            frontend/tests/ai/results/integration_tests_generated*.json
          retention-days: 14

  # ==================== Refactoring ====================
  refactoring:
    name: Code Refactoring Suggestions
    runs-on: ubuntu-latest
    if: github.event.inputs.run_refactor == 'true'
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install anthropic

      - name: Run Refactoring Agent on Key Files
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Refactor key service files
          for file in app/services/*.py; do
            if [ -f "../../../backend/$file" ]; then
              python backend/refactor_agent.py "$file" || true
            fi
          done
        continue-on-error: true

      - name: Upload Refactoring Suggestions
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: refactoring-suggestions
          path: |
            frontend/tests/ai/suggestions/refactored_*.py
            frontend/tests/ai/results/refactor_report_*.md
          retention-days: 14

  # ==================== E2E Tests ====================
  e2e-tests:
    name: Playwright E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: abvtrends
          POSTGRES_PASSWORD: abvtrends
          POSTGRES_DB: abvtrends_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Python dependencies
        run: pip install anthropic

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Install Playwright browsers
        working-directory: frontend
        run: npx playwright install --with-deps chromium

      - name: Install backend dependencies
        working-directory: backend
        run: pip install -r requirements.txt
        continue-on-error: true

      - name: Start backend server
        working-directory: backend
        env:
          DATABASE_URL: postgresql://abvtrends:abvtrends@localhost:5432/abvtrends_test
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
        continue-on-error: true

      - name: Build frontend
        working-directory: frontend
        run: npm run build
        continue-on-error: true

      - name: Run Playwright tests
        working-directory: frontend
        env:
          NEXT_PUBLIC_API_URL: http://localhost:8000
        run: npm run test:e2e
        continue-on-error: true

      - name: Run AI Self-Healing on Failures
        working-directory: frontend/tests/ai
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python run_claude_tests.py --skip-run
        continue-on-error: true

      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-results
          path: |
            frontend/tests/playwright/reports/
            frontend/tests/ai/results/
            frontend/tests/ai/suggestions/
          retention-days: 14

  # ==================== Summary Report ====================
  summary:
    name: Generate Summary Report
    runs-on: ubuntu-latest
    needs: [backend-analysis, security-scan, e2e-tests]
    if: always()
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
        continue-on-error: true

      - name: Generate GitHub Summary
        run: |
          echo "# ğŸ¤– AI Engineering Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Job Results" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Analysis | ${{ needs.backend-analysis.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.e2e-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Available Reports" >> $GITHUB_STEP_SUMMARY
          echo "- Model Audit Report" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Analysis" >> $GITHUB_STEP_SUMMARY
          echo "- Security Report" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- AI Self-Healing Suggestions" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Download artifacts from the Actions tab for full reports." >> $GITHUB_STEP_SUMMARY

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const results = {
              'backend-analysis': '${{ needs.backend-analysis.result }}',
              'security-scan': '${{ needs.security-scan.result }}',
              'e2e-tests': '${{ needs.e2e-tests.result }}'
            };

            const emoji = (status) => status === 'success' ? 'âœ…' : status === 'failure' ? 'âŒ' : 'â­ï¸';

            let body = '## ğŸ¤– AI Engineering Pipeline Results\n\n';
            body += '| Analysis | Status |\n|----------|--------|\n';
            for (const [job, status] of Object.entries(results)) {
              body += `| ${job} | ${emoji(status)} ${status} |\n`;
            }
            body += '\nğŸ“Š Full reports available in [Actions artifacts](' +
              `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      - name: Upload Combined Report
        uses: actions/upload-artifact@v4
        with:
          name: ai-engineering-report
          path: artifacts/
          retention-days: 30
